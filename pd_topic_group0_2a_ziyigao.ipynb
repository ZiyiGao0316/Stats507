{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6448b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf90aa8",
   "metadata": {},
   "source": [
    "\n",
    "Ziyi Gao\n",
    "\n",
    "ziyigao@umich.edu\n",
    "\n",
    "## Multi-indexing\n",
    "\n",
    "- Aiming at sophisticated data analysis and manipulation, especially for working with higher dimensional data\n",
    "- Enabling one to store and manipulate data with an arbitrary number of dimensions in lower dimensional data structures\n",
    "\n",
    "## Creating a multi-indexing dataframe and Reconstructing\n",
    "\n",
    "- It can be created from:\n",
    "    - a list of arrays (using MultiIndex.from_arrays())\n",
    "    - an array of tuples (using MultiIndex.from_tuples())\n",
    "    - a crossed set of iterables (using MultiIndex.from_product())\n",
    "    - a DataFrame (using MultiIndex.from_frame())\n",
    "- The method get_level_values() will return a vector of the labels for each location at a particular level\n",
    "\n",
    "## Basic Indexing\n",
    "\n",
    "- Advantages of hierarchical indexing\n",
    "    - hierarchical indexing can select data by a “partial” label identifying a subgroup in the data\n",
    "- Defined Levels\n",
    "    - keeps all the defined levels of an index, even if they are not actually used\n",
    "    \n",
    "## Data Alignment and Using Reindex\n",
    "\n",
    "- Operations between differently-indexed objects having MultiIndex on the axes will work as you expect; data alignment will work the same as an Index of tuples\n",
    "- The reindex() method of Series/DataFrames can be called with another MultiIndex, or even a list or array of tuples:\n",
    "\n",
    "## Some Advanced Indexing\n",
    "\n",
    "Syntactically integrating MultiIndex in advanced indexing with .loc is a bit challenging\n",
    "\n",
    "- In general, MultiIndex keys take the form of tuples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "### Q0 code example\n",
    "\n",
    "#created from arrays or tuples\n",
    "\n",
    "arrays = [[\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "          [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"]]\n",
    "tuples = list(zip(*arrays)) # if from arrays, this step is dropped\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"first\", \"second\"]) \n",
    "# if from arrays, use pd.MultiIndex.from_arrays()\n",
    "\n",
    "df1 = pd.Series(np.random.randn(8), index=index)\n",
    "\n",
    "#created from product\n",
    "\n",
    "iterables = [[\"bar\", \"baz\", \"foo\", \"qux\"], [\"one\", \"two\"]]\n",
    "df2 = pd.MultiIndex.from_product(iterables, names=[\"first\", \"second\"])\n",
    "\n",
    "#created directly from dataframe\n",
    "df3 = pd.DataFrame([[\"bar\", \"one\"], [\"bar\", \"two\"], [\"foo\", \"one\"], [\"foo\", \"two\"]],\n",
    "                  columns=[\"first\", \"second\"])\n",
    "pd.MultiIndex.from_frame(df)\n",
    "\n",
    "#Basic Operation and Reindex\n",
    "\n",
    "df1 + df1[:2]\n",
    "df1 + df1[::2]\n",
    "\n",
    "df1.reindex(index[:3])\n",
    "df1.reindex([(\"foo\", \"two\"), (\"bar\", \"one\"), (\"qux\", \"one\"), (\"baz\", \"one\")])\n",
    "\n",
    "#Advanced Indexing \n",
    "df1 = df1.T\n",
    "df1.loc[(\"bar\", \"two\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270863e",
   "metadata": {},
   "source": [
    "## Topics in Pandas\n",
    "**Stats 507, Fall 2021** \n",
    "  \n",
    "\n",
    "## Contents\n",
    "Add a bullet for each topic and link to the level 2 title header using \n",
    "the exact title with spaces replaced by a dash. \n",
    "\n",
    "+ [Pandas Query](#Pandas-Query) \n",
    "+ [Time Series](#Time-Series) \n",
    "+ [Window Functions](#Window-Functions) \n",
    "\n",
    "## Pandas Query ##\n",
    "\n",
    "### pd. query ##\n",
    "\n",
    "###### Name: Anandkumar Patel\n",
    "###### Email: patelana@umich.edu\n",
    "###### Unique ID: patelana\n",
    "\n",
    "### Arguments and Output\n",
    "\n",
    "**Arguments** \n",
    "\n",
    "* expression (expr) \n",
    "* inplace (default = False) \n",
    "    * Do you want to operate directly on the dataframe or create new one\n",
    "* kwargs (keyword arguments)\n",
    "\n",
    "**Returns** \n",
    "* Dataframe from provided query\n",
    "\n",
    "## Why\n",
    "\n",
    "* Similar to an SQL query \n",
    "* Can help you filter data by querying\n",
    "* Returns a subset of the DataFrame\n",
    "* loc and iloc can be used to query either rows or columns\n",
    "\n",
    "## Query Syntax\n",
    "\n",
    "* yourdataframe.query(expression, inplace = True/False\n",
    "\n",
    "## Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404b79b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': range(1, 6),\n",
    "                   'B': range(10, 0, -2),\n",
    "                   'C C': range(10, 5, -1)})\n",
    "print(df)\n",
    "\n",
    "print('Below is the results of the query')\n",
    "\n",
    "print(df.query('A > B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47f4ac",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "**Name: Lu Qin**\n",
    "UM email: qinlu@umich.edu\n",
    "\n",
    "### Overview\n",
    " - Data times\n",
    " - Time Frequency\n",
    " - Time zone\n",
    "\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35881b13",
   "metadata": {},
   "source": [
    "### Datetime\n",
    " - Parsing time series information from various sources and formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.to_datetime(\n",
    "    [\"20/10/2021\", \n",
    "     np.datetime64(\"2021-10-20\"), \n",
    "     datetime.datetime(2021, 10, 20)]\n",
    ")\n",
    "\n",
    "dti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad6571",
   "metadata": {},
   "source": [
    "### Time frequency\n",
    "- Generate sequences of fixed-frequency dates and time spans\n",
    "- Resampling or converting a time series to a particular frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9d87a",
   "metadata": {},
   "source": [
    "#### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ca0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = pd.date_range(\"2021-10-20\", periods=2, freq=\"H\")\n",
    "\n",
    "dti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeeb8ff",
   "metadata": {},
   "source": [
    "#### convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(\"2021-10-20\", periods=3, freq=\"H\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1f4e3",
   "metadata": {},
   "source": [
    "#### resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample(\"2H\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cddf2bc",
   "metadata": {},
   "source": [
    "### Timezone\n",
    " - Manipulating and converting date times with timezone information\n",
    " - `tz_localize()`\n",
    " - `tz_convert()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = dti.tz_localize(\"UTC\")\n",
    "dti\n",
    "\n",
    "dti.tz_convert(\"US/Pacific\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa41b1",
   "metadata": {},
   "source": [
    "## Window Functions ##\n",
    "**Name: Stephen Toner** \\\n",
    "UM email: srtoner@umich.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc0a35",
   "metadata": {},
   "source": [
    "Of the many funcitons in Pandas, one which is particularly useful for time\n",
    "series analysis is the window function. It lets us apply some aggregation \n",
    "function over a specified lookback period on a rolling basis throughout the\n",
    "time series. This is particularly useful for financial analsyis of equity\n",
    "returns, so we will compute some financial metrics for Amazon stock using\n",
    "this techinique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90544d11",
   "metadata": {},
   "source": [
    "Our first step is to import our data for Amazon (\"AMZN\") \n",
    "over a healthy time horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc040b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "amzn_data = web.DataReader(\"AMZN\", \n",
    "                           data_source = 'yahoo', \n",
    "                           start = \"2016-10-01\", \n",
    "                           end = \"2021-10-01\")\n",
    "\n",
    "amzn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814aebe",
   "metadata": {},
   "source": [
    "While the column labels are largely self-explanatory, two important notes\n",
    "should be made:\n",
    "* The adjusted close represents the closing price after all is said and done\n",
    "after the trading session ends; this may represent changes due to accounts \n",
    "being settled / netted against each other, or from adjustments to financial\n",
    "reporting statements.\n",
    "* One reason for our choice in AMZN stock rather than others is that AMZN\n",
    "has not had a stock split in the last 20 years; for this reason we do not\n",
    "need to concern ourselves with adjusting for the issuance of new shares like\n",
    "we would for TSLA, AAPL, or other companies with large\n",
    "market capitalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39f5c0",
   "metadata": {},
   "source": [
    "Getting back to Pandas, we have three main functions that allow us to\n",
    "perform Window operations:\n",
    "* `df.shift()`: Not technically a window operation, but helpful for\n",
    "computing calculations with offsets in time series\n",
    "* `rolling`: For a given fixed lookback period, tells us the \n",
    "aggregation metric (mean, avg, std dev)\n",
    "* `expanding`: Similar to `rolling`, but the lookback period is not fixed. \n",
    "Helpful when we want to have a variable lookback period such as \"month to \n",
    "date\" returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87a2cc",
   "metadata": {},
   "source": [
    "Two metrics that are often of interest to investors are the returns of an\n",
    "asset and the volume of shares traded. Returns are either calculated on\n",
    "a simple basis:\n",
    "$$ R_s = P_1/P_0 -1$$\n",
    "or a log basis:\n",
    "$$ R_l = \\log (P_1 / P_2) $$\n",
    "Simple returns are more useful when aggregating returns across multiple \n",
    "assets, while Log returns are more flexible when looking at returns across \n",
    "time. As we are just looking at AMZN, we will calculate the log returns\n",
    "using the `shift` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daaf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_data[\"l_returns\"] = np.log(amzn_data[\"Adj Close\"]/\n",
    "                                amzn_data[\"Adj Close\"].shift(1))\n",
    "\n",
    "\n",
    "plt.title(\"Log Returns of AMZN\")\n",
    "plt.plot(amzn_data['l_returns'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d03e9b",
   "metadata": {},
   "source": [
    "For the latter, we see that the\n",
    "volume of AMZN stock traded is quite noisy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Daily Trading Volume of AMZN\")   \n",
    "plt.plot(amzn_data['Volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04c7a7",
   "metadata": {},
   "source": [
    "If we want to get a better picture of the trends, we can always take a\n",
    "moving average of the last 5 days (last full set of trading days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_data[\"vol_5dma\"] = amzn_data[\"Volume\"].rolling(window = 5).mean()\n",
    "plt.title(\"Daily Trading Volume of AMZN\")   \n",
    "plt.plot(amzn_data['vol_5dma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e3085",
   "metadata": {},
   "source": [
    "When we apply this to a price metric, we can identify some technical patterns\n",
    "such as when the 15 or 50 day moving average crosses the 100 or 200 day\n",
    "moving average (known as the golden cross, by those who believe in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff2c8e",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "amzn_data[\"ma_15\"] = amzn_data[\"Adj Close\"].rolling(window = 15).mean()\n",
    "amzn_data[\"ma_100\"] = amzn_data[\"Adj Close\"].rolling(window = 100).mean()\n",
    "\n",
    "fig1 = plt.figure()\n",
    "plt.plot(amzn_data[\"ma_15\"])\n",
    "plt.plot(amzn_data[\"ma_100\"])\n",
    "plt.title(\"15 Day MA vs. 100 Day MA\")\n",
    "\n",
    "# We can then use the `shift()` method to identify which dates have \n",
    "# golden crosses\n",
    "\n",
    "gc_days = (amzn_data.eval(\"ma_15 > ma_100\") & \n",
    "               amzn_data.shift(1).eval(\"ma_15 <= ma_100\"))\n",
    "\n",
    "gc_prices = amzn_data[\"ma_15\"][gc_days]\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(amzn_data[\"Adj Close\"], color = \"black\")\n",
    "plt.scatter( x= gc_prices.index, \n",
    "                y = gc_prices[:],\n",
    "                marker = \"+\", \n",
    "                color = \"gold\" \n",
    "                )\n",
    "\n",
    "plt.title(\"Golden Crosses & Adj Close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf3c25",
   "metadata": {},
   "source": [
    "The last feature that Pandas offers is a the `expanding` window function, \n",
    "which calculates a metric over a time frame that grows with each additional \n",
    "period. This is particularly useful for backtesting financial metrics\n",
    "as indicators of changes in equity prices: because one must be careful not\n",
    "to apply information from the future when performing backtesting, the \n",
    "`expanding` functionality helps ensure we only use information up until the \n",
    "given point in time. Below, we use the expanding function to plot cumulative\n",
    "return of AMZN over the time horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba4be5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def calc_total_return(x):\n",
    "    \"\"\"    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    \"\"\"\n",
    "    return np.log(x[-1] / x[0]) \n",
    "\n",
    "\n",
    "amzn_data[\"Total Returns\"] = (amzn_data[\"Adj Close\"]\n",
    "                              .expanding()\n",
    "                              .apply(calc_total_return))\n",
    "\n",
    "fig3 = plt.figure()\n",
    "ax5 = fig3.add_subplot(111)\n",
    "ax5 = plt.plot(amzn_data[\"Total Returns\"])\n",
    "plt.title(\"Cumulative Log Returns for AMZN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b39c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Contents\n",
    "Add a bullet for each topic and link to the level 2 title header using \n",
    "the exact title with spaces replaced by a dash. \n",
    "\n",
    "+ [Topic Title](#Topic-Title)\n",
    "+ [Topic 2 Title](#Topic-2-Title)\n",
    "\n",
    "## Topic Title\n",
    "Include a title slide with a short title for your content.\n",
    "Write your name in *bold* on your title slide. \n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "+ [Processing Time Data](#Processing-Time-Data)\n",
    "+ [Topic 2 Title](#Topic-2-Title)\n",
    "\n",
    "* ###  Processing Time Data\n",
    "\n",
    "**Yurui Chang**\n",
    "\n",
    "#### Pandas.to_timedelta\n",
    "\n",
    "- To convert a recognized timedelta format / value into a Timedelta type\n",
    "- the unit of the arg\n",
    "  * 'W'\n",
    "  * 'D'/'days'/'day'\n",
    "  * ‘hours’ / ‘hour’ / ‘hr’ / ‘h’\n",
    "  * ‘m’ / ‘minute’ / ‘min’ / ‘minutes’ / ‘T’\n",
    "  * ‘S’ / ‘seconds’ / ‘sec’ / ‘second’\n",
    "  * ‘ms’ / ‘milliseconds’ / ‘millisecond’ / ‘milli’ / ‘millis’ / ‘L’\n",
    "  * ‘us’ / ‘microseconds’ / ‘microsecond’ / ‘micro’ / ‘micros’ / ‘U’\n",
    "  * ‘ns’ / ‘nanoseconds’ / ‘nano’ / ‘nanos’ / ‘nanosecond’ / ‘N’\n",
    "\n",
    "* Parsing a single string to a Timedelta\n",
    "* Parsing a list or array of strings\n",
    "* Converting numbers by specifying the unit keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0df4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timedelta('1 days 06:05:01.000030'), Timedelta('0 days 00:00:15.500000')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex(['0 days', '1 days', '2 days', '3 days', '4 days'], dtype='timedelta64[ns]', freq=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = pd.to_timedelta('1 days 06:05:01.00003')\n",
    "time2 = pd.to_timedelta('15.5s')\n",
    "print([time1, time2])\n",
    "pd.to_timedelta(['1 days 06:05:01.00003', '15.5s', 'nan'])\n",
    "\n",
    "pd.to_timedelta(np.arange(5), unit='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbe48f",
   "metadata": {},
   "source": [
    "#### pandas.to_datetime\n",
    "\n",
    "* To convert argument to datetime\n",
    "* Returns: datetime, return type dependending on input\n",
    "  * list-like: DatetimeIndex\n",
    "  * Series: Series of datetime64 dtype\n",
    "  * scalar: Timestamp\n",
    "* Assembling a datetime from multiple columns of a DataFrame\n",
    "* Converting Pandas Series to datetime w/ custom format\n",
    "* Converting Unix integer (days) to datetime\n",
    "* Convert integer (seconds) to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ab622",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['date is 01199002',\n",
    "           'date is 02199015',\n",
    "           'date is 03199020',\n",
    "           'date is 09199204'])\n",
    "pd.to_datetime(s, format=\"date is %m%Y%d\")\n",
    "\n",
    "time1 = pd.to_datetime(14554, unit='D', origin='unix')\n",
    "print(time1)\n",
    "time2 = pd.to_datetime(1600355888, unit='s', origin='unix')\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211372a",
   "metadata": {},
   "source": [
    "# Title: Pandas Time Series Analysis\n",
    "## Name: Kenan Alkiek (kalkiek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Read in the air quality dataset\n",
    "air_quality = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/air_quality_no2_long.csv')\n",
    "air_quality[\"datetime\"] = pd.to_datetime(air_quality[\"date.utc\"])\n",
    "\n",
    "# One common method of dealing with time series data is to set the index equal to the data\n",
    "air_quality = air_quality.set_index('datetime')\n",
    "air_quality.head()\n",
    "\n",
    "# Plot the NO2 Over time for Paris france\n",
    "paris_air_quality = air_quality[(air_quality['city'] == 'Paris') & (air_quality['country'] == 'FR')]\n",
    "\n",
    "paris_air_quality.plot()\n",
    "plt.ylabel(\"$NO_2 (µg/m^3)$\")\n",
    "\n",
    "# Plot average NO2 by hour of the day\n",
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "air_quality.groupby(\"date.utc\")[\"value\"].mean().plot(kind='bar', rot=0, ax=axs)\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"$NO_2 (µg/m^3)$\")\n",
    "plt.show()\n",
    "\n",
    "# Limit the data between 2 dates\n",
    "beg_of_june = paris_air_quality[\"2019-06-01\":\"2019-06-03\"]\n",
    "beg_of_june.plot()\n",
    "plt.ylabel(\"$NO_2 (µg/m^3)$\")\n",
    "\n",
    "# Resample the Data With a Different Frequency (and Aggregration)\n",
    "monthly_max = air_quality.resample(\"M\").max()\n",
    "print(monthly_max)\n",
    "\n",
    "# Ignore weekends and certain times\n",
    "rng = pd.date_range('20190501 09:00', '20190701 16:00', freq='30T')\n",
    "\n",
    "# Grab only certain times\n",
    "rng = rng.take(rng.indexer_between_time('09:30', '16:00'))\n",
    "\n",
    "# Remove weekends\n",
    "rng = rng[rng.weekday < 5]\n",
    "\n",
    "rng.to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae6c56",
   "metadata": {},
   "source": [
    "## Pivot Table in pandas\n",
    "\n",
    "\n",
    "*Mingjia Chen* \n",
    "mingjia@umich.edu\n",
    "\n",
    "- A pivot table is a table format that allows data to be dynamically arranged and summarized in categories.\n",
    "- Pivot tables are flexible, allowing you to customize your analytical calculations and making it easy for users to understand the data.\n",
    "- Use the following example to illustrate how a pivot table works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c165e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2, 3, 4, 5],\n",
    "                   \"B\": [0, 1, 0, 1, 0],\n",
    "                   \"C\": [1, 2, 2, 3, 3],\n",
    "                   \"D\": [2, 4, 5, 5, 6],\n",
    "                   \"E\": [2, 2, 4, 4, 6]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673a7e8",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- The simplest pivot table must have a data frame and an index.\n",
    "- In addition, you can also have multiple indexes.\n",
    "- Try to swap the order of the two indexes, the data results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = pd.pivot_table(df,index=[\"A\"])\n",
    "tab2 = pd.pivot_table(df,index=[\"A\", \"B\"])\n",
    "tab3 = pd.pivot_table(df,index=[\"B\", \"A\"])\n",
    "print(tab1)\n",
    "print(tab2)\n",
    "print(tab3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da285f5d",
   "metadata": {},
   "source": [
    "## Values \n",
    "- Change the values parameter can filter the data for the desired calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3172cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df,index=[\"B\", \"A\"], values=[\"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ae486",
   "metadata": {},
   "source": [
    "## Aggfunc\n",
    "\n",
    "- The aggfunc parameter sets the function that we perform when aggregating data.\n",
    "- When we do not set aggfunc, it defaults aggfunc='mean' to calculate the mean value.\n",
    "  - When we also want to get the sum of the data under indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df,index=[\"B\", \"A\"], values=[\"C\", \"D\"], aggfunc=[np.sum,np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d079b1e",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "- columns like index can set the column hierarchy field, it is not a required parameter, as an optional way to split the data.\n",
    "\n",
    "- fill_value fills empty values, margins=True for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df,index=[\"B\"],columns=[\"E\"], values=[\"C\", \"D\"],\n",
    "               aggfunc=[np.sum], fill_value=0, margins=1)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "markdown"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
